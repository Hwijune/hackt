{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed2fec83",
   "metadata": {},
   "source": [
    "<font color='tomato'><font color=\"#CC3D3D\"><p>\n",
    "# Multi-VAE: Multinomial Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcb5160",
   "metadata": {},
   "source": [
    "- 이 노트북에서는 이해하기 쉬운 구현을 위해 원 논문과 달리 `KL annealing`을 사용하지 않고 `Epoch 당 NDCG`도 측정하지 않았음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beddc9eb",
   "metadata": {},
   "source": [
    "<img align='left' src='http://drive.google.com/uc?export=view&id=18eJwXBwp_Dwj9j70Dhbg9_Zys37IbVuk' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b829fb9",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ad4645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers, Input, Model, losses, optimizers, initializers\n",
    "\n",
    "# 4주차에 제공한 msr.zip(ms recommenders 패키지 일부) 사용 시 아래 절차에 따라야 함.\n",
    "import sys\n",
    "sys.path.append('/home/work/yhcho/2023-02/RS')  # 본인이 msr.zip 압축을 푼 위치를 확인(셀에서 pwd 명령어 실행) 후 변경해야 함. \n",
    "                                                # 윈도우에서는 폴더 구분자를 // 또는 \\\\로 해야 함.  \n",
    "from msr.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "from msr.constants import (\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_ITEM_COL,\n",
    "    DEFAULT_RATING_COL,\n",
    "    DEFAULT_PREDICTION_COL,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8799dfb7",
   "metadata": {},
   "source": [
    "### Load & Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06100c8",
   "metadata": {},
   "source": [
    "프로젝트의 범위에는 사용자와 항목 간의 상호 작용과 1에서 5까지의 정수 등급으로 구성된 MovieLens 데이터 세트가 사용됨. 무비렌즈를 이진화된 클릭 매트릭스(1: 사용자가 이 영화를 좋아함, 0: 사용자가 이 영화를 좋아하지 않거나 시청/평가하지 않음)로 변환하고, 홀드아웃 사용자 데이터를 기반으로 평가함.\n",
    "  - 평점 3.5 미만의 사용자와 영화 간 상호작용(평점)은 제외\n",
    "  - 5개 미만의 영화를 클릭한 사용자는 제외\n",
    "  - 어떤 사용자도 클릭하지 않은 영화도 제외\n",
    "\n",
    "훈련/검증 세트는 모든 훈련/검증 사용자의 전체 히스토리를 포함하는 클릭 행렬 형태로 모델에 입력되나, 테스트 세트는 다시 훈련과 테스트 부분으로 분할해야 함. 결과적으로 4개의 데이터 세트를 생성:\n",
    " - train\n",
    " - valid\n",
    " - test_tr\n",
    " - test_te (with the original ratings)\n",
    "\n",
    "학습된 모델에 'test_tr'을 넣어 만들어지는 'reconstructed_test_tr' 데이터를 아래의 지표를 사용하여 'test_te'와 비교:\n",
    " - MAP@k\n",
    " - NDCG@k\n",
    " - Recall@k\n",
    " - Precision@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e2320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test_tr, test_te = pd.read_pickle('MultiVAE_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a59c06",
   "metadata": {},
   "source": [
    "### Parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc006dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_DIM = train.shape[1] # Number of items\n",
    "INTERMEDIATE_DIM = 600    # Dimension of intermediate space\n",
    "LATENT_DIM = 200          # Dimension of latent space\n",
    "DROP_RATE = 0.5           # Dropout percentage of the encoder\n",
    "BETA = 0.1                # A constant parameter β in the ELBO function, when you are not using annealing (annealing=False)\n",
    "TOP_K = 10                # Number of top k items per user\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0409e66",
   "metadata": {},
   "source": [
    "### Build the Multi-VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6c229f",
   "metadata": {},
   "source": [
    "##### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=(ITEM_DIM,), name=\"encoder_input\")\n",
    "x = layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(encoder_input)  # output = x / sqrt(max(sum(x**2), epsilon))\n",
    "x = layers.Dropout(DROP_RATE)(x)\n",
    "x = layers.Dense(INTERMEDIATE_DIM, activation=\"tanh\", # 논문에서는 activation 함수로 tanh 사용\n",
    "                 kernel_initializer=initializers.GlorotUniform(), # Xavier Initialization for weights\n",
    "                 bias_initializer=initializers.TruncatedNormal(mean=0.0, stddev=0.001) # Normal Initialization for Biases\n",
    "                )(x)\n",
    "z_mean = layers.Dense(LATENT_DIM, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(LATENT_DIM, name=\"z_log_var\")(x)\n",
    "\n",
    "# Sampling(Reparameterization)\n",
    "# VAE의 학습과 최적화 과정에서 수치적 안정성과 효율성을 향상시키기 위해 분산 대신 로그분산(log variance)을 사용 \n",
    "def sampling(args): \n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = tf.random.normal(shape=(tf.shape(z_mean)[0], LATENT_DIM), mean=0., stddev=0.1)\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "encoder_output = layers.Lambda(sampling)([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc233e5",
   "metadata": {},
   "source": [
    "##### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f84e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Dense(INTERMEDIATE_DIM, activation=\"tanh\", # 논문에서는 activation 함수로 tanh 사용\n",
    "                 kernel_initializer=initializers.GlorotUniform(), # Xavier Initialization for weights\n",
    "                 bias_initializer=initializers.TruncatedNormal(mean=0.0, stddev=0.001) # Normal Initialization for Biases\n",
    "                )(encoder_output) \n",
    "x = layers.Dropout(DROP_RATE)(x)\n",
    "decoder_output = layers.Dense(ITEM_DIM, activation='linear')(x) # Loss 계산에서 softmax를 사용하기 때문에 activation 안함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d380b9",
   "metadata": {},
   "source": [
    "##### Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605ac258",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Model(encoder_input, decoder_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506911c9",
   "metadata": {},
   "source": [
    "### Train the Multi-VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e083d93f",
   "metadata": {},
   "source": [
    "##### Multi-VAE Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d9c143",
   "metadata": {},
   "source": [
    "- Multi-VAE의 Loss = \n",
    "Reconstruction loss(Cross entropy loss) + Beta(0~1 사이의 값) * KL Divergence loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac0fe99",
   "metadata": {},
   "source": [
    "**1. 크로스 엔트로피 손실:**\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{N} \\sum_{j=1}^{N} H(p_j, q_j) = \\frac{1}{N} \\sum_{j=1}^{N} -\\sum_{i} p_j(i) \\log q_j(i)\n",
    "$$\n",
    "\n",
    "여기서 $p_j(i)$는 $j$번째 데이터 포인트의 실제 레이블의 확률 값, $q_j(i)$는 $j$번째 데이터 포인트에 대한 모델의 예측 확률 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcf994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReconstLoss(y_true, y_pred):\n",
    "    log_softmax_var = tf.nn.log_softmax(y_pred) # log(q(i)) 계산\n",
    "    neg_ll = -tf.reduce_mean(                   # −1/N*∑p(i)*log(q(i)) 계산\n",
    "        tf.reduce_sum(                          # ∑p(i)*log(q(i)) 계산\n",
    "            log_softmax_var * y_true,           # p(i)*log(q(i)) 계산\n",
    "            axis=-1)\n",
    "    )\n",
    "    return neg_ll\n",
    "#    return ITEM_DIM * keras.metrics.binary_crossentropy(y_true, y_pred)  # 출력층 softmax일 경우\n",
    "\n",
    "# 위 ReconstLoss를 기본 loss로 설정\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss=ReconstLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff39edb4",
   "metadata": {},
   "source": [
    "**2. KL 발산 손실:**\n",
    "$$ \\text{KL loss} = -\\frac{1}{2} \\times \\sum_{i} \\left( 1 + z_{\\text{log_var}, i} - z_{\\text{mean}, i}^2 - \\exp(z_{\\text{log_var}, i}) \\right) $$\n",
    "\n",
    "- KL발산(KL divergence)은 한 확률분포가 다른 분포와 얼마나 다른지를 측정하는 방법\n",
    "- VAE에서 평균이 z_mean이고 분산이 z_log_var인 정규분포가 표준정규분포와 얼마나 다른지 측정 \n",
    "- 표준정규분포에서 크게 벗어난 z_mean과 z_log_var 변수로 인코딩하는 네트워크에 penalty(규제)를 부여\n",
    "- 재구성 손실(reconstruction loss)에 KL발산을 더해야 함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841c9e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KL divergence loss\n",
    "kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)\n",
    "\n",
    "# Final Loss = Reconstruction loss(model.compile에서 지정) + Beta * KL divergence loss(model.add_loss에서 지정)\n",
    "model.add_loss(BETA * tf.reduce_mean(kl_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f0bed8",
   "metadata": {},
   "source": [
    "##### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a86fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hist = model.fit(train, train, validation_data=(valid, valid), epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ff9e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot Learning Curves\n",
    "plt.plot(hist.history['loss'], label=\"train\")\n",
    "plt.plot(hist.history['val_loss'], label=\"valid\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77cc191",
   "metadata": {},
   "source": [
    "### Evaluate the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b8ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Recommenders contributors.\n",
    "# Licensed under the MIT License.\n",
    "\n",
    "def recommend_k_items(model, x, k, remove_seen=True):\n",
    "    \"\"\"Returns the top-k items ordered by a relevancy score.\n",
    "    Obtained probabilities are used as recommendation score.\n",
    "\n",
    "    Args:\n",
    "        x (numpy.ndarray, int32): rating matrix.\n",
    "        k (scalar, int32): the number of items to recommend.\n",
    "    Returns:\n",
    "        numpy.ndarray, float: A sparse matrix containing the top_k elements ordered by their score.\n",
    "    \"\"\"\n",
    "    # obtain scores\n",
    "    score = model.predict(x)\n",
    "\n",
    "    if remove_seen:\n",
    "        # if true, it removes items from the train set by setting them to zero\n",
    "        seen_mask = np.not_equal(x, 0)\n",
    "        score[seen_mask] = 0\n",
    "    # get the top k items\n",
    "    top_items = np.argpartition(-score, range(k), axis=1)[:, :k]\n",
    "    # get a copy of the score matrix\n",
    "    score_c = score.copy()\n",
    "    # set to zero the k elements\n",
    "    score_c[np.arange(score_c.shape[0])[:, None], top_items] = 0\n",
    "    # set to zeros all elements other then the k\n",
    "    top_scores = score - score_c\n",
    "    return top_scores\n",
    "\n",
    "def map_back_sparse(x, kind):\n",
    "    \"\"\"Map back the rating matrix to a pd dataframe\n",
    "\n",
    "    Args:\n",
    "        x (numpy.ndarray, int32): rating matrix\n",
    "        kind (string): specify if the output values are ratings or predictions\n",
    "    Returns:\n",
    "        pandas.DataFrame: the generated pandas dataframe\n",
    "    \"\"\"\n",
    "    m, n = x.shape\n",
    "\n",
    "    # 1) Create a DF from a sparse matrix\n",
    "    # obtain the non zero items\n",
    "    items = [np.asanyarray(np.where(x[i, :] != 0)).flatten() for i in range(m)]\n",
    "    ratings = [x[i, items[i]] for i in range(m)]  # obtain the non-zero ratings\n",
    "\n",
    "    # Creates user ids following the DF format\n",
    "    userids = []\n",
    "    for i in range(0, m):\n",
    "        userids.extend([i] * len(items[i]))\n",
    "\n",
    "    # Flatten the lists to follow the DF input format\n",
    "    items = list(itertools.chain.from_iterable(items))\n",
    "    ratings = list(itertools.chain.from_iterable(ratings))\n",
    "\n",
    "    if kind == \"ratings\":\n",
    "        col_out = DEFAULT_RATING_COL\n",
    "    else:\n",
    "        col_out = DEFAULT_PREDICTION_COL\n",
    "\n",
    "    # create a df\n",
    "    out_df = pd.DataFrame.from_dict(\n",
    "        {DEFAULT_USER_COL: userids, DEFAULT_ITEM_COL: items, col_out: ratings}\n",
    "    )\n",
    "    return out_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca06cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model prediction on the training part of test set \n",
    "top_k =  recommend_k_items(model, test_tr, k=TOP_K, remove_seen=True)\n",
    "\n",
    "# Convert sparse matrix back to df\n",
    "top_k_df = map_back_sparse(top_k, kind='prediction')\n",
    "test_df = map_back_sparse(test_te, kind='ratings') # use 'test_te' with the original ratings\n",
    "\n",
    "# Use the ranking metrics for evaluation\n",
    "eval_map = map_at_k(test_df, top_k_df, col_prediction='prediction', k=TOP_K)\n",
    "eval_ndcg = ndcg_at_k(test_df, top_k_df, col_prediction='prediction', k=TOP_K)\n",
    "eval_precision = precision_at_k(test_df, top_k_df, col_prediction='prediction', k=TOP_K)\n",
    "eval_recall = recall_at_k(test_df, top_k_df, col_prediction='prediction', k=TOP_K)\n",
    "\n",
    "print(\"MAP@10:\\t\\t%f\" % eval_map,\n",
    "      \"NDCG@10:\\t%f\" % eval_ndcg,\n",
    "      \"Precision@10:\\t%f\" % eval_precision,\n",
    "      \"Recall@10: \\t%f\" % eval_recall, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ce87c",
   "metadata": {},
   "source": [
    "<font color='tomato'><font color=\"#CC3D3D\"><p>\n",
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch2.0,Tensorflow2.12 (kaggle v135 23.07/ Python Conda 3.10,CUDA 11.8) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
