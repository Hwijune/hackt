{"cells":[{"cell_type":"markdown","id":"140be9fe","metadata":{"id":"140be9fe"},"source":["<font color='tomato'><font color=\"#CC3D3D\"><p>\n","# Data Preprocessing for AE-based RecSys"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p5EVm5UtFxJi","executionInfo":{"status":"ok","timestamp":1698477223436,"user_tz":-540,"elapsed":2618,"user":{"displayName":"hwi","userId":"07964455913579077797"}},"outputId":"120fad95-df65-443c-c08e-ea65d0c2705f"},"id":"p5EVm5UtFxJi","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","id":"6d5c67f6","metadata":{"id":"6d5c67f6"},"source":["### Global Setting & Imports"]},{"cell_type":"code","execution_count":10,"id":"95d5e676","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":386},"id":"95d5e676","executionInfo":{"status":"error","timestamp":1698477270803,"user_tz":-540,"elapsed":300,"user":{"displayName":"hwi","userId":"07964455913579077797"}},"outputId":"38682be4-e62b-4e99-a26b-0004fa05389e"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-9bd21e76b873>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_splitters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy_stratified_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_evaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmap_at_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndcg_at_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_at_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_at_k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAffinityMatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbinarize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'msr.sparse'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import numpy as np\n","import pandas as pd\n","import sys, os\n","from pathlib import Path\n","import tensorflow as tf\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","sys.path.append('/content/drive/Othercomputers/mypc/study/10_RecSystem/msr')\n","\n","from msr.constants import (\n","    DEFAULT_USER_COL,\n","    DEFAULT_ITEM_COL,\n","    DEFAULT_RATING_COL,\n","    DEFAULT_TIMESTAMP_COL,\n","    DEFAULT_PREDICTION_COL,\n",")\n","from msr.split_utils import min_rating_filter_pandas\n","from msr.python_splitters import numpy_stratified_split\n","from msr.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n","from msr.sparse import AffinityMatrix\n","from msr.python_utils import binarize"]},{"cell_type":"code","execution_count":null,"id":"59608eb7","metadata":{"id":"59608eb7"},"outputs":[],"source":["HELDOUT_USERS = 600  # 검증 및 평가용 사용자 수\n","SEED = 2023"]},{"cell_type":"markdown","id":"a573d4ab","metadata":{"id":"a573d4ab"},"source":["### Data Loading"]},{"cell_type":"code","execution_count":null,"id":"60956127","metadata":{"id":"60956127"},"outputs":[],"source":["# MovieLens 1M 데이터 다운로드 & 압축 해제\n","path = os.getcwd()\n","movielens_zipped_file = tf.keras.utils.get_file(\n","    path + \"/ml-1m.zip\",\n","    \"http://files.grouplens.org/datasets/movielens/ml-1m.zip\",\n","    extract=True, cache_subdir='movielens', cache_dir=path\n",")"]},{"cell_type":"code","execution_count":null,"id":"b74e6d7c","metadata":{"id":"b74e6d7c"},"outputs":[],"source":["# 포맷에 맞춰 평점 데이터 로딩\n","file_name = Path(path + '/movielens/ml-1m/ratings.dat')\n","cols = [DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL]\n","df = pd.read_table(file_name, sep='::', header=None, names=cols, engine='python')\n","df"]},{"cell_type":"markdown","id":"9e6623cb","metadata":{"id":"9e6623cb"},"source":["### Data Filtering"]},{"cell_type":"code","execution_count":null,"id":"dfda2cd4","metadata":{"id":"dfda2cd4"},"outputs":[],"source":["# Binarize the data (only keep ratings >= 4)\n","df_preferred = df[df['rating'] > 3.5]\n","print (df_preferred.shape)\n","df_low_rating = df[df['rating'] <= 3.5]\n","\n","df_preferred.head(10)"]},{"cell_type":"code","execution_count":null,"id":"05fc4e18","metadata":{"id":"05fc4e18"},"outputs":[],"source":["# Keep users who clicked on at least 5 movies\n","df = min_rating_filter_pandas(df_preferred, min_rating=5, filter_by=\"user\")\n","\n","# Keep movies that were clicked on by at least on 1 user\n","df = min_rating_filter_pandas(df, min_rating=1, filter_by=\"item\")"]},{"cell_type":"code","execution_count":null,"id":"1a1157a1","metadata":{"id":"1a1157a1"},"outputs":[],"source":["# Obtain both usercount and itemcount after filtering\n","usercount = df[[DEFAULT_USER_COL]].groupby(DEFAULT_USER_COL, as_index = False).size()\n","itemcount = df[[DEFAULT_ITEM_COL]].groupby(DEFAULT_ITEM_COL, as_index = False).size()\n","\n","# Compute sparsity after filtering\n","sparsity = 1. * df.shape[0] / (usercount.shape[0] * itemcount.shape[0])\n","\n","print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" %\n","      (df.shape[0], usercount.shape[0], itemcount.shape[0], sparsity * 100))"]},{"cell_type":"markdown","id":"5d773c37","metadata":{"id":"5d773c37"},"source":["### Data Splitting"]},{"cell_type":"code","execution_count":null,"id":"d3b9779b","metadata":{"id":"d3b9779b"},"outputs":[],"source":["unique_users = sorted(df[DEFAULT_USER_COL].unique())\n","np.random.seed(SEED)\n","unique_users = np.random.permutation(unique_users)"]},{"cell_type":"code","execution_count":null,"id":"a25c75bb","metadata":{"id":"a25c75bb"},"outputs":[],"source":["# Create train/validation/test users\n","n_users = len(unique_users)\n","print(\"Number of unique users:\", n_users)\n","\n","train_users = unique_users[:(n_users - HELDOUT_USERS * 2)]\n","print(\"\\nNumber of training users:\", len(train_users))\n","\n","val_users = unique_users[(n_users - HELDOUT_USERS * 2) : (n_users - HELDOUT_USERS)]\n","print(\"\\nNumber of validation users:\", len(val_users))\n","\n","test_users = unique_users[(n_users - HELDOUT_USERS):]\n","print(\"\\nNumber of test users:\", len(test_users))"]},{"cell_type":"code","execution_count":null,"id":"11a6d79a","metadata":{"id":"11a6d79a"},"outputs":[],"source":["# For training set keep only users that are in train_users list\n","train_set = df.loc[df[DEFAULT_USER_COL].isin(train_users)]\n","print(\"Number of training observations: \", train_set.shape[0])\n","\n","# For validation set keep only users that are in val_users list\n","val_set = df.loc[df[DEFAULT_USER_COL].isin(val_users)]\n","print(\"\\nNumber of validation observations: \", val_set.shape[0])\n","\n","# For test set keep only users that are in test_users list\n","test_set = df.loc[df[DEFAULT_USER_COL].isin(test_users)]\n","print(\"\\nNumber of test observations: \", test_set.shape[0])\n","\n","# train_set/val_set/test_set contain user - movie interactions with rating 4 or 5"]},{"cell_type":"code","execution_count":null,"id":"277df056","metadata":{"id":"277df056"},"outputs":[],"source":["# Obtain list of unique movies used in training set\n","unique_train_items = pd.unique(train_set[DEFAULT_ITEM_COL])\n","print(\"Number of unique movies that rated in training set\", unique_train_items.size)"]},{"cell_type":"code","execution_count":null,"id":"b6b72f9b","metadata":{"id":"b6b72f9b"},"outputs":[],"source":["# For validation set keep only movies that used in training set\n","val_set = val_set.loc[val_set[DEFAULT_ITEM_COL].isin(unique_train_items)]\n","print(\"Number of validation observations after filtering: \", val_set.shape[0])\n","\n","# For test set keep only movies that used in training set\n","test_set = test_set.loc[test_set[DEFAULT_ITEM_COL].isin(unique_train_items)]\n","print(\"\\nNumber of test observations after filtering: \", test_set.shape[0])"]},{"cell_type":"markdown","id":"c4874d48","metadata":{"id":"c4874d48"},"source":["### Click matrix (binary rating matrix) Generating"]},{"cell_type":"code","execution_count":null,"id":"ef31ead3","metadata":{"id":"ef31ead3"},"outputs":[],"source":["# Instantiate the sparse matrix generation for train, validation and test sets\n","# use list of unique items from training set for all sets\n","train, _, _ = AffinityMatrix(df=train_set, items_list=unique_train_items).gen_affinity_matrix()\n","valid, _, _ = AffinityMatrix(df=val_set, items_list=unique_train_items).gen_affinity_matrix()\n","test, _, _  = AffinityMatrix(df=test_set, items_list=unique_train_items).gen_affinity_matrix()"]},{"cell_type":"code","execution_count":null,"id":"c4bd13da","metadata":{"id":"c4bd13da"},"outputs":[],"source":["# Split test data into training and testing parts\n","test_tr, test_te = numpy_stratified_split(test, ratio=0.75, seed=SEED)"]},{"cell_type":"code","execution_count":null,"id":"d963353d","metadata":{"id":"d963353d"},"outputs":[],"source":["# Binarize train and validation\n","train = binarize(a=train, threshold=3.5)\n","valid = binarize(a=valid, threshold=3.5)\n","\n","# Binarize test data: training part\n","test_tr = binarize(a=test_tr, threshold=3.5)\n","# Binarize test data: testing part (save non-binary version in the separate object, will be used for calculating NDCG)"]},{"cell_type":"code","execution_count":null,"id":"67ffece4","metadata":{"id":"67ffece4"},"outputs":[],"source":["# Save data all together using pickle\n","import pickle\n","with open('MultiVAE_data_v2.pkl', 'wb') as f:\n","    vae_data = (train, valid, test_tr, test_te)\n","    pickle.dump(vae_data, f)"]},{"cell_type":"markdown","id":"10027bea","metadata":{"id":"10027bea"},"source":["<font color='tomato'><font color=\"#CC3D3D\"><p>\n","# End"]}],"metadata":{"kernelspec":{"display_name":"Pytorch2.0,Tensorflow2.12 (kaggle v135 23.07/ Python Conda 3.10,CUDA 11.8) on Backend.AI","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}