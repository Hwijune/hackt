{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1H4v4MQxZT1JLODrGqROhys-n9aJE5wSZ","authorship_tag":"ABX9TyOihIbMc0/69Wt2t9vrm2PE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9eb05944fae247eaa355497bfbcc6ce1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b86cf224462d4b388b2f0637f8dcf5ad","IPY_MODEL_6e52aabf79a5426c9550f9222aed9cd6","IPY_MODEL_d37270da31c6407092b266ee65622ff8"],"layout":"IPY_MODEL_f019ea8fc64945be99111850c3292e7e"}},"b86cf224462d4b388b2f0637f8dcf5ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83807d544573475a80df47061be639db","placeholder":"​","style":"IPY_MODEL_b6a5773fe1c6450e87ccb7ba71543566","value":"Downloading (…)B-chat-gguf-q4_0.bin: 100%"}},"6e52aabf79a5426c9550f9222aed9cd6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d2d987fbb8d4aa790483600d7c3c38b","max":3907169536,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a7073d6d868d40e9b0591bface8d4acb","value":3907169536}},"d37270da31c6407092b266ee65622ff8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f3b020e536a466c9f25fcdffe0946c4","placeholder":"​","style":"IPY_MODEL_0a69eba28b4448f6af0376c5473ea6dd","value":" 3.91G/3.91G [00:38&lt;00:00, 128MB/s]"}},"f019ea8fc64945be99111850c3292e7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83807d544573475a80df47061be639db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6a5773fe1c6450e87ccb7ba71543566":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d2d987fbb8d4aa790483600d7c3c38b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7073d6d868d40e9b0591bface8d4acb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6f3b020e536a466c9f25fcdffe0946c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a69eba28b4448f6af0376c5473ea6dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g_bQ0wWlg4nh","executionInfo":{"status":"ok","timestamp":1694223151670,"user_tz":-540,"elapsed":6099,"user":{"displayName":"hwi","userId":"07964455913579077797"}},"outputId":"17c7960b-bc1e-4872-ac0c-31d376d0e572"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install transformers auto-gptq"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mUtz8SLBg7NC","executionInfo":{"status":"ok","timestamp":1694222835316,"user_tz":-540,"elapsed":6994,"user":{"displayName":"hwi","userId":"07964455913579077797"}},"outputId":"65353592-7fa3-42ce-ccc6-0888f216ad4c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.1)\n","Requirement already satisfied: auto-gptq in /usr/local/lib/python3.10/dist-packages (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: accelerate>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.22.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.14.5)\n","Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.0.1)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.0.1+cu118)\n","Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.5.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.19.0->auto-gptq) (5.9.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->auto-gptq) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->auto-gptq) (16.0.6)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (9.0.0)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (1.5.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.3.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.70.15)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.8.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto-gptq) (1.16.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2023.3.post1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\n"]}]},{"cell_type":"code","source":["import os\n","os.environ['TRANSFORMERS_CACHE'] = \\\n","'/content/drive/Othercomputers/내 노트북/study/09_GenerativeAI'"],"metadata":{"id":"kCcRMjCOiCxx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import pipeline\n","from auto_gptq import AutoGPTQForCausalLM\n","model_id = \"j5ng/kullm-5.8b-GPTQ-8bit\"\n","model = AutoGPTQForCausalLM.from_quantized(\n","model_id, device=\"cuda:0\", use_triton=False)\n","pipe = pipeline('text-generation', model=model,tokenizer=model_id)"],"metadata":{"id":"XjSUng_riI6a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipe('대형 언어 모델은', max_length=64, eos_token_id=2, pad_token_id=2)"],"metadata":{"id":"aYGRlQCtjqGL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install llama-cpp-python huggingface_hub"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vGlNJKHlmgj1","executionInfo":{"status":"ok","timestamp":1694223766491,"user_tz":-540,"elapsed":65070,"user":{"displayName":"hwi","userId":"07964455913579077797"}},"outputId":"fe0ab4c3-a7a6-4f9b-d5a1-66abd34fe636"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting llama-cpp-python\n","  Downloading llama_cpp_python-0.1.83.tar.gz (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.16.4)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.5.0)\n","Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.23.5)\n","Collecting diskcache>=5.6.1 (from llama-cpp-python)\n","  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.12.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2023.7.22)\n","Building wheels for collected packages: llama-cpp-python\n","  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.1.83-cp310-cp310-linux_x86_64.whl size=411022 sha256=0cd1b86da2103bc035ade41fdae35059847385be6132a66ffa7caef78a7ee5b5\n","  Stored in directory: /root/.cache/pip/wheels/3f/39/6f/3e75230ce84bb465df194bca6c0c7b936dc4b0b3c83389688d\n","Successfully built llama-cpp-python\n","Installing collected packages: diskcache, llama-cpp-python\n","Successfully installed diskcache-5.6.3 llama-cpp-python-0.1.83\n"]}]},{"cell_type":"code","source":["from huggingface_hub import hf_hub_download\n","cache_dir = '/content/drive/Othercomputers/내 노트북/study/09_GenerativeAI'\n","filename = 'Llama-2-ko-7B-chat-gguf-q4_0.bin'\n","hf_hub_download(\n","repo_id='StarFox7/Llama-2-ko-7B-chat-gguf',\n","filename=filename, local_dir=cache_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["9eb05944fae247eaa355497bfbcc6ce1","b86cf224462d4b388b2f0637f8dcf5ad","6e52aabf79a5426c9550f9222aed9cd6","d37270da31c6407092b266ee65622ff8","f019ea8fc64945be99111850c3292e7e","83807d544573475a80df47061be639db","b6a5773fe1c6450e87ccb7ba71543566","8d2d987fbb8d4aa790483600d7c3c38b","a7073d6d868d40e9b0591bface8d4acb","6f3b020e536a466c9f25fcdffe0946c4","0a69eba28b4448f6af0376c5473ea6dd"]},"id":"xW4byDG1mmk0","executionInfo":{"status":"ok","timestamp":1694223813545,"user_tz":-540,"elapsed":39670,"user":{"displayName":"hwi","userId":"07964455913579077797"}},"outputId":"7eeec4f4-fcb7-4ed0-9856-3ca48bf52c54"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)B-chat-gguf-q4_0.bin:   0%|          | 0.00/3.91G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9eb05944fae247eaa355497bfbcc6ce1"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/Othercomputers/내 노트북/study/09_GenerativeAI/Llama-2-ko-7B-chat-gguf-q4_0.bin'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["from llama_cpp import Llama\n","llm = Llama(model_path=\"/content/drive/Othercomputers/내 노트북/study/09_GenerativeAI/cache_dir/Llama-2-ko-7B-chat-gguf-q4_0.bin\", n_ctx=1024)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NJg1Ugo-mwDp","executionInfo":{"status":"ok","timestamp":1694223866161,"user_tz":-540,"elapsed":772,"user":{"displayName":"hwi","userId":"07964455913579077797"}},"outputId":"7abd70b5-7142-4f45-a613-bdbc803ae130"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"]}]},{"cell_type":"code","source":["llm('대형 언어 모델은')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GMkOjibNmyRY","executionInfo":{"status":"ok","timestamp":1694223969974,"user_tz":-540,"elapsed":101225,"user":{"displayName":"hwi","userId":"07964455913579077797"}},"outputId":"fc507414-e264-40d9-e767-d6c799002673"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'id': 'cmpl-f37dc313-b610-489a-b4b4-4889da5f8f3c',\n"," 'object': 'text_completion',\n"," 'created': 1694223834,\n"," 'model': '/content/drive/Othercomputers/내 노트북/study/09_GenerativeAI/Llama-2-ko-7B-chat-gguf-q4_0.bin',\n"," 'choices': [{'text': ' 방대한 양의 텍스트 데이터를 기반으로 패턴을 학습하여 새로운 문장을 생성하거나 기존 데이터를 분류하는 데 사용됩니다. 이 알고리즘은 자연어 이해(Natural Language Understanding) 분야를 넘어 기계 번역, 음성 인식, 컴퓨터 비전 등 여러 응용 분야로 확산되고 있습니다.\\u200b특히 코로나19 팬데믹 이후 언택트 환경이 가속화됨에 따라 온라인 비즈니스에 인공지능 기술을 적용한 기업도 등장했습니다. 2016년 설립된 영국의 인공지능 스타트업인 아레나(Arena)는 고객에게 전화 상담 전화가 아닌 챗봇을 통해 의료 서비스를',\n","   'index': 0,\n","   'logprobs': None,\n","   'finish_reason': 'length'}],\n"," 'usage': {'prompt_tokens': 5, 'completion_tokens': 128, 'total_tokens': 133}}"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["!pip install openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DYT7AV9bvTGo","executionInfo":{"status":"ok","timestamp":1694226022708,"user_tz":-540,"elapsed":4749,"user":{"displayName":"hwi","userId":"07964455913579077797"}},"outputId":"153294bf-3af1-44f9-ceae-97a64269f6e4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai\n","  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n","Installing collected packages: openai\n","Successfully installed openai-0.28.0\n"]}]},{"cell_type":"code","source":["import openai\n","openai.api_key = open('/content/drive/Othercomputers/내 노트북/study/09_GenerativeAI/key.txt').read().strip()"],"metadata":{"id":"QsJ58Fs7vWfC","executionInfo":{"status":"ok","timestamp":1694226080960,"user_tz":-540,"elapsed":316,"user":{"displayName":"hwi","userId":"07964455913579077797"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["response = openai.ChatCompletion.create(\n","model=\"gpt-3.5-turbo\",\n","messages=[{\"role\": \"user\", \"content\": \"대형 언어 모델은\"}],\n","temperature=1, max_tokens=256, top_p=1,\n","frequency_penalty=0, presence_penalty=0)"],"metadata":{"id":"3PDwVZ_0vorO","executionInfo":{"status":"ok","timestamp":1694226099540,"user_tz":-540,"elapsed":6360,"user":{"displayName":"hwi","userId":"07964455913579077797"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["response.choices[0].message.content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"GxsG6DXPvroO","executionInfo":{"status":"ok","timestamp":1694226105038,"user_tz":-540,"elapsed":19,"user":{"displayName":"hwi","userId":"07964455913579077797"}},"outputId":"de05cb27-4ee3-437b-a57d-b5b99800d2f4"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'많은 양의 텍스트 데이터를 학습하여 자연어 처리 과제를 수행하는 딥 러닝 기반 모델입니다. 이 모델은 수억 건의 문장과 관련된 맥락을 이해하여 자연스러운 문장을 생성하거나 자연어 이해, 번역, 요약, 질의 응답, 감성 분석 등 다양한 자연어 처리 작업을 수행할 수 있습니다.\\n\\n대표적으로 GPT (Generative Pre-trained Transformer) 모델은 BERT (Bidirectional Encoder Representations from Transformers) 모델을 기반으로 구축되어 있으며, OpenAI에서 개발한 모델입니다. GPT는 다수의 계층 (layer)과 어텐션 메커니즘을 사용하여 문장의 표현을 학습하며, 문장 내의 단어들 간의 관계를 파'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["!pip install langchain"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f305EWT_vvEi","executionInfo":{"status":"ok","timestamp":1694226125705,"user_tz":-540,"elapsed":7179,"user":{"displayName":"hwi","userId":"07964455913579077797"}},"outputId":"ef19567e-3bef-4ac0-aa8d-a2769afcf5ab"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain\n","  Downloading langchain-0.0.285-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.20)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n","  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n","Collecting langsmith<0.1.0,>=0.0.21 (from langchain)\n","  Downloading langsmith-0.0.35-py3-none-any.whl (37 kB)\n","Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.5)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.12)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: mypy-extensions, marshmallow, typing-inspect, langsmith, dataclasses-json, langchain\n","Successfully installed dataclasses-json-0.5.14 langchain-0.0.285 langsmith-0.0.35 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"]}]},{"cell_type":"code","source":["from langchain.llms import OpenAI\n","OPENAI_API_KEY = open('/content/drive/Othercomputers/내 노트북/study/09_GenerativeAI/key.txt').read().strip()\n","llm = OpenAI(openai_api_key=OPENAI_API_KEY)"],"metadata":{"id":"bS4LRSa_vx8L","executionInfo":{"status":"ok","timestamp":1694226154382,"user_tz":-540,"elapsed":8,"user":{"displayName":"hwi","userId":"07964455913579077797"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["llm.predict('안녕')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"gPkrv7b0v6P3","executionInfo":{"status":"ok","timestamp":1694226164869,"user_tz":-540,"elapsed":484,"user":{"displayName":"hwi","userId":"07964455913579077797"}},"outputId":"37e5268c-08ef-487a-d4e1-24d1b79a2a70"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'하세요\\n\\n반갑습니다.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["from langchain.chat_models import ChatOpenAI\n","chat_model = ChatOpenAI(openai_api_key= OPENAI_API_KEY)\n","chat_model.predict(\"안녕\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"fo1Dj82Iv8TD","executionInfo":{"status":"ok","timestamp":1694226174583,"user_tz":-540,"elapsed":1934,"user":{"displayName":"hwi","userId":"07964455913579077797"}},"outputId":"5f15da42-0a22-456d-8c29-99432f69d939"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'안녕하세요! 저는 OpenAI의 AI 어시스턴트입니다. 도움이 필요하신 것이 있으신가요?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["from langchain.schema import AIMessage, HumanMessage, SystemMessage\n","response = chat_model.predict_messages([\n","SystemMessage(content=\"너는 메뉴 고르는 것을 도와주는 AI이다.\"),\n","HumanMessage(content='오늘 점심 뭐먹지?'),\n","AIMessage(content='a) 짜장면 b) 국밥'),\n","HumanMessage(content='b가 좋네.'),\n","])"],"metadata":{"id":"B-vdp3VWv_nl","executionInfo":{"status":"ok","timestamp":1694226188947,"user_tz":-540,"elapsed":1240,"user":{"displayName":"hwi","userId":"07964455913579077797"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from langchain.prompts.chat import (ChatPromptTemplate,\n","SystemMessagePromptTemplate, HumanMessagePromptTemplate)"],"metadata":{"id":"AU-jA9s_wDDi","executionInfo":{"status":"ok","timestamp":1694226200768,"user_tz":-540,"elapsed":2,"user":{"displayName":"hwi","userId":"07964455913579077797"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["sys_msg_temp = SystemMessagePromptTemplate.from_template(\n","\"\"\"사용자가 카테고리를 입력하면 {num_example}개의 예시를 대답해라.\n","대답은 콤마로 구분된 리스트로 출력해라.\n","리스트 이외의 다른 문장은 출력하지 마라.\"\"\")\n","human_msg_temp = HumanMessagePromptTemplate.from_template(\"{category}\")\n","chat_prompt = ChatPromptTemplate.from_messages([sys_msg_temp, human_msg_temp])"],"metadata":{"id":"F4AEUoG-wE5e","executionInfo":{"status":"ok","timestamp":1694226334175,"user_tz":-540,"elapsed":301,"user":{"displayName":"hwi","userId":"07964455913579077797"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["chat_prompt = ChatPromptTemplate.from_messages([\n","('system',\n","\"\"\"사용자가 카테고리를 입력하면 {num_example}개의 예시를 대답해라.\n"," 대답은 콤마로 구분된 리스트로 출력해라.\n"," 리스트 이외의 다른 문장은 출력하지 마라.\"\"\"),\n","('human', \"{category}\")\n","])"],"metadata":{"id":"1meJHySWwHeZ","executionInfo":{"status":"ok","timestamp":1694226517972,"user_tz":-540,"elapsed":285,"user":{"displayName":"hwi","userId":"07964455913579077797"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["messages = chat_prompt.format_messages(\n","num_example=5, category=\"색깔\")"],"metadata":{"id":"bWvgjh6AwJ33","executionInfo":{"status":"ok","timestamp":1694226526176,"user_tz":-540,"elapsed":302,"user":{"displayName":"hwi","userId":"07964455913579077797"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["print(messages)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hgFxbJEexU3C","executionInfo":{"status":"ok","timestamp":1694226538432,"user_tz":-540,"elapsed":7,"user":{"displayName":"hwi","userId":"07964455913579077797"}},"outputId":"cd57e486-9d40-41a0-f0fd-178d8ad6e8c0"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["[SystemMessage(content='사용자가 카테고리를 입력하면 5개의 예시를 대답해라.\\n 대답은 콤마로 구분된 리스트로 출력해라.\\n 리스트 이외의 다른 문장은 출력하지 마라.', additional_kwargs={}), HumanMessage(content='색깔', additional_kwargs={}, example=False)]\n"]}]},{"cell_type":"code","source":["from langchain.schema import BaseOutputParser\n","\n","class CommaSeparatedListOutputParser(BaseOutputParser):\n","  #\"\"\"쉼표로 구분된 목록을 리스트로 변환\"\"\"\n","  def parse(self, text: str):\n","    return text.strip().split(\", \")\n","CommaSeparatedListOutputParser().parse(\"hi, bye\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I-aARHU4wqla","executionInfo":{"status":"ok","timestamp":1694226560511,"user_tz":-540,"elapsed":295,"user":{"displayName":"hwi","userId":"07964455913579077797"}},"outputId":"c6110ee6-5e1a-43ab-f8f0-33478eb029b5"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['hi', 'bye']"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["from langchain.chains import LLMChain\n","chain = LLMChain(\n","llm=chat_model,\n","prompt=chat_prompt,\n","output_parser=CommaSeparatedListOutputParser()\n",")"],"metadata":{"id":"-HGeduL1wtzi","executionInfo":{"status":"ok","timestamp":1694226564650,"user_tz":-540,"elapsed":2,"user":{"displayName":"hwi","userId":"07964455913579077797"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["chain.run(num_example=3, category=\"음식\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BQLsncf7wwrG","executionInfo":{"status":"ok","timestamp":1694226587376,"user_tz":-540,"elapsed":2012,"user":{"displayName":"hwi","userId":"07964455913579077797"}},"outputId":"de5f5ea7-6773-4ffb-eadc-33d70edccb2e"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['1. 피자', '스파게티', '햄버거\\n2. 불고기', '비빔밥', '김치찌개\\n3. 초밥', '라멘', '돈까스']"]},"metadata":{},"execution_count":30}]}]}